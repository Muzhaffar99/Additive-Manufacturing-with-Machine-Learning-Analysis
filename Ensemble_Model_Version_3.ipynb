{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x_Ir0imBm-PK","colab":{"base_uri":"https://localhost:8080/","height":714},"outputId":"c2850bb3-9fbb-4c7c-d43c-ab8cbd1d9fcc","executionInfo":{"status":"error","timestamp":1715571445129,"user_tz":-60,"elapsed":42555,"user":{"displayName":"Muzhaffar Maruf Ibrahim","userId":"13211234798137897760"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Shareddrives/ACS6403 - Group Project/Deliverable 5 Final Project Report/Prediction Model\n","'Copy of Poly_model_0.joblib'\t       'Copy of SVM_model_6.joblib'\n","'Copy of Poly_model_1.joblib'\t       'Copy of SVM_model_7.joblib'\n","'Copy of Poly_model_2.joblib'\t       'Copy of System_model_1.joblib'\n","'Copy of Poly_model_3.joblib'\t       'Copy of System_model_2.joblib'\n","'Copy of Poly_model_4.joblib'\t       'Copy of System_model_3.joblib'\n","'Copy of Poly_model_5.joblib'\t       'Copy of System_model_4.joblib'\n","'Copy of Poly_model_6.joblib'\t       'Copy of System_model_5.joblib'\n","'Copy of Poly_model_7.joblib'\t       'Copy of System_model_6.joblib'\n","'Copy of randomforest_model_1.joblib'  'Copy of System_model_7.joblib'\n","'Copy of randomforest_model_2.joblib'  'Deep Feedforward Network'\n","'Copy of randomforest_model_3.joblib'   input_data_normalized.csv\n","'Copy of randomforest_model_4.joblib'   input_data_normalized.txt\n","'Copy of randomforest_model_5.joblib'   model_results.pdf\n","'Copy of randomforest_model_6.joblib'   model_text_summary.pdf\n","'Copy of randomforest_model_7.joblib'   output_data_normalized.csv\n","'Copy of SVM_model_1.joblib'\t        output_data_normalized.txt\n","'Copy of SVM_model_2.joblib'\t       'Polynomial Regression'\n","'Copy of SVM_model_3.joblib'\t       'Random Forest'\n","'Copy of SVM_model_4.joblib'\t       'Support Vector Machine.ipynb'\n","'Copy of SVM_model_5.joblib'\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'VARResults' object has no attribute 'predict'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-933c741241c4>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Copy of {algo_name}_model_{index}.joblib'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/base/wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'VARResults' object has no attribute 'predict'"]}],"source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from joblib import dump\n","import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from joblib import load\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from joblib import dump\n","from sklearn.multioutput import MultiOutputClassifier\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change directory to the location of the file\n","%cd /content/drive/Shareddrives/ACS6403 - Group Project/Deliverable 5 Final Project Report/Prediction Model/\n","\n","# List the files to confirm\n","!ls\n","\n","input_data_1 = '/content/drive/Shareddrives/ACS6403 - Group Project/Preprocessed Data/input_data.txt'  # Update the path\n","output_data_1 = '/content/drive/Shareddrives/ACS6403 - Group Project/Preprocessed Data/output_data.txt'  # Update the path\n","\n","# Load the input and output data\n","input_Data = pd.read_csv(input_data_1, sep=',')\n","input_Data.columns = ['Input 1', 'Input 2', 'Input 3']\n","\n","output_Data = pd.read_csv(output_data_1, sep='\\s+')\n","output_Data.columns = ['Output 1', 'Output 2', 'Output 3', 'Output 4', 'Output 5', 'Output 6', 'Output 7']\n","\n","# Initialize MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Scale input and output data\n","input_Data_normalized = scaler.fit_transform(input_Data)\n","input_Data_normalized = pd.DataFrame(input_Data_normalized, columns=input_Data.columns)\n","output_Data_normalized = scaler.fit_transform(output_Data)\n","output_Data_normalized = pd.DataFrame(output_Data_normalized, columns=output_Data.columns)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(input_Data_normalized, output_Data_normalized, test_size=0.2, random_state=42)\n","\n","# List of algorithms\n","algorithms =  ['Poly','randomforest','SVM','System']\n","\n","# Load models and store their predictions\n","all_predictions = []\n","\n","for algo_name in algorithms:\n","    for index in range(1, 7):  # Assuming there are 7 models per algorithm\n","        filename = f'Copy of {algo_name}_model_{index}.joblib'\n","        model = load(filename)\n","        predictions = model.predict(X_test)\n","        all_predictions.append(predictions.reshape(-1, 1))\n","\n","# Combine all predictions into a single matrix\n","\n","combined_predictions = np.hstack(all_predictions)\n","print(combined_predictions)\n","\n","# Train-test split or cross-validation setup should be used here to avoid leakage\n","# For simplicity, using a direct split example, ideally use cross-validation\n","X_train, X_test, y_train, y_test = train_test_split(input_Data_normalized, output_Data_normalized, test_size=0.2, random_state=42)\n","\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","X_train_preds, X_test_preds, y_train_preds, y_test_preds = train_test_split(combined_predictions, y_test, test_size=0.5, random_state=42)\n","print(\"X_train_preds shape:\", X_train_preds.shape)\n","print(\"y_train_preds shape:\", y_train_preds.shape)"]},{"cell_type":"code","source":["# Assuming y_train_preds and y_test_preds are pandas DataFrames\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","models = []\n","mse_scores = []\n","mae_scores = []\n","\n","# Ensure the correct handling of DataFrame indexing\n","num_outputs = y_train_preds.shape[1]  # Number of output columns\n","\n","for i in range(num_outputs):\n","    model = Sequential()\n","    model.add(Dense(10, input_dim=X_train_preds.shape[1], activation='relu'))\n","    model.add(Dense(10, activation='relu'))\n","    model.add(Dense(1))  # Single output neuron, as we're predicting one column at a time\n","\n","    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n","\n","    # Use .iloc to correctly index DataFrame by rows for all rows (:), and column i\n","    model.fit(X_train_preds, y_train_preds.iloc[:, i], epochs=50, batch_size=10, verbose=0)\n","    pred = model.predict(X_test_preds)\n","\n","    mse = mean_squared_error(y_test_preds.iloc[:, i], pred)\n","    mae = mean_absolute_error(y_test_preds.iloc[:, i], pred)\n","    models.append(model)\n","    mse_scores.append(mse)\n","    mae_scores.append(mae)\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.scatter(y_test_preds.iloc[:, i], pred.flatten(), edgecolor='k', alpha=0.6)\n","    plt.plot(y_test_preds.iloc[:, i], y_test_preds.iloc[:, i], 'r--')\n","    plt.title(f'Regression Results for Output Column {i+1}')\n","    plt.xlabel('Actual Values')\n","    plt.ylabel('Predicted Values')\n","    plt.show()\n","\n","    print(f'MSE for output column {i+1}: {mse}')\n","    print(f'MAE for output column {i+1}: {mae}')\n","\n","average_mse = np.mean(mse_scores)\n","average_mae = np.mean(mae_scores)\n","print(f'Average Mean Squared Error: {average_mse}')\n","print(f'Average Mean Absolute Error: {average_mae}')"],"metadata":{"id":"5AhKajfpBA6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(models.append)"],"metadata":{"id":"lvBgWSSQ3nN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install SALib\n","\n","import numpy as np\n","from SALib.sample import saltelli\n","from SALib.analyze import sobol\n","import matplotlib.pyplot as plt\n","\n","problem = {\n","    'num_vars': X_train_preds.shape[1],\n","    'names': [f'feature{i}' for i in range(X_train_preds.shape[1])],\n","    'bounds': [[0, 1] for _ in range(X_train_preds.shape[1])]\n","}\n","\n","num_samples = 1000  # Define the number of samples you want to generate\n","param_values = saltelli.sample(problem, num_samples, calc_second_order=True)\n","\n","model = model\n","\n","def evaluate_model(X):\n","    predictions = model.predict(X)\n","    return predictions.flatten()  # Flatten the predictions if necessary\n","\n","Y = np.array([evaluate_model(param_values[i].reshape(1, -1)) for i in range(param_values.shape[0])])\n","\n","Si = sobol.analyze(problem, Y, print_to_console=False)\n","\n","# Print the first order and total sensitivity indices\n","print(\"First order sensitivity indices:\", Si['S1'])\n","print(\"Total sensitivity indices:\", Si['ST'])\\\n","# Visualize the results\n","plt.figure(figsize=(10, 5))  # This line was pointed out in the error\n","plt.bar(problem['names'], Si['S1'], label='First Order Indices')\n","plt.bar(problem['names'], Si['ST'], bottom=Si['S1'], label='Total Indices')\n","plt.xlabel('Input Features')\n","plt.ylabel('Sensitivity Indices')\n","plt.title('Global Sensitivity Analysis Results')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"wLJTg6Yf8n-q"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}