{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":433,"status":"ok","timestamp":1715296101168,"user":{"displayName":"Muzhaffar Maruf Ibrahim","userId":"13211234798137897760"},"user_tz":-60},"id":"SrZHQ_PC-zmZ","outputId":"49e0f9d0-ca74-4677-fa11-95271b24d5f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[3.231500e+02 1.000000e-05 6.132245e-03]\n"," [3.231500e+02 1.000000e-05 1.225449e-02]\n"," [3.231500e+02 1.000000e-05 1.837673e-02]\n"," ...\n"," [9.731500e+02 2.000000e-01 2.877555e-01]\n"," [9.731500e+02 2.000000e-01 2.938778e-01]\n"," [9.731500e+02 2.000000e-01 3.000000e-01]]\n","[[-4.7338106e+04 -1.0599773e+04 -2.7131550e+04 ...  1.4517185e-25\n","   5.9826421e-25  1.3981116e-05]\n"," [-4.7308263e+04 -1.0616659e+04 -2.5240740e+04 ...  1.5486813e-25\n","   7.6536221e-25  1.3943969e-05]\n"," [-4.7278894e+04 -1.0633829e+04 -2.4122189e+04 ...  1.6521204e-25\n","   9.7692130e-25  1.3906912e-05]\n"," ...\n"," [-6.3567739e+04 -4.8424248e+04 -6.3107304e+04 ...  3.3099485e-11\n","   1.4352324e-10  1.5758037e-05]\n"," [-6.3601686e+04 -4.8488750e+04 -6.2971021e+04 ...  3.3810930e-11\n","   1.4741547e-10  1.5725362e-05]\n"," [-6.3635113e+04 -4.8554450e+04 -6.2837199e+04 ...  3.4537655e-11\n","   1.5129962e-10  1.5692779e-05]]\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","3\n","7\n"]}],"source":["# import libraries and data\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n","from sklearn.metrics import confusion_matrix\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, Activation\n","from keras import optimizers, regularizers\n","import seaborn as sns\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import KFold\n","from statistics import mean\n","\n","# set random seed for more reproducible results\n","np.random.seed(1)\n","\n","# read the data using pandas csv read\n","\n","input_data_1 = '/content/drive/Shareddrives/ACS6403 - Group Project/Preprocessed Data/input_data.txt'  # Update the path\n","output_data_1 = '/content/drive/Shareddrives/ACS6403 - Group Project/Preprocessed Data/output_data.txt'  # Update the path\n","\n","input_data = pd.read_csv(input_data_1, sep=',')\n","output_data = pd.read_csv(output_data_1, sep='\\s+')\n","\n","# convert pandas dataframe to a numpy array\n","Input_data_raw = np.array(input_data)\n","Output_data_raw = np.array(output_data)\n","\n","print(Input_data_raw)\n","print(Output_data_raw)\n","\n","# scaler = StandardScaler()           # define scaling function\n","scaler = MinMaxScaler()\n","Input = scaler.fit_transform(Input_data_raw)         # standardize input data\n","Output = scaler.fit_transform(Output_data_raw)         # standardize output data\n","num_input_features = Input.shape[1]           # number of features\n","num_output_features = Output.shape[1]            # number of classes\n","\n","print(Input)\n","print(Output)\n","\n","print(num_input_features)\n","print(num_output_features)\n","\n","# # split the data set into training and validation sets\n","# X_train, X_val, Y_train, Y_val = train_test_split(Input, Output,\n","# test_size=0.25, random_state=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1715296102478,"user":{"displayName":"Muzhaffar Maruf Ibrahim","userId":"13211234798137897760"},"user_tz":-60},"id":"BkVWZME9hads","outputId":"f8bc3b7d-7e50-4c8c-d792-a23440d03ef4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1715296102701,"user":{"displayName":"Muzhaffar Maruf Ibrahim","userId":"13211234798137897760"},"user_tz":-60},"id":"hgbZ4vYr-1Gb","outputId":"1cdc5b35-336d-480e-cc4f-8e376538c1a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 64)                256       \n","                                                                 \n"," batch_normalization_6 (Bat  (None, 64)                256       \n"," chNormalization)                                                \n","                                                                 \n"," activation_6 (Activation)   (None, 64)                0         \n","                                                                 \n"," dense_9 (Dense)             (None, 48)                3120      \n","                                                                 \n"," batch_normalization_7 (Bat  (None, 48)                192       \n"," chNormalization)                                                \n","                                                                 \n"," activation_7 (Activation)   (None, 48)                0         \n","                                                                 \n"," dense_10 (Dense)            (None, 16)                784       \n","                                                                 \n"," batch_normalization_8 (Bat  (None, 16)                64        \n"," chNormalization)                                                \n","                                                                 \n"," activation_8 (Activation)   (None, 16)                0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_11 (Dense)            (None, 7)                 119       \n","                                                                 \n","=================================================================\n","Total params: 4791 (18.71 KB)\n","Trainable params: 4535 (17.71 KB)\n","Non-trainable params: 256 (1.00 KB)\n","_________________________________________________________________\n"]}],"source":["#3rd run best 0.05\n","model2 = Sequential()\n","\n","model2.add(Dense(64, kernel_regularizer=regularizers.L2(l2=0.005), input_shape=(num_input_features,)))\n","model2.add(BatchNormalization())\n","model2.add(Activation(\"gelu\"))\n","\n","model2.add(Dense(48, kernel_regularizer=regularizers.L2(l2=0.005)))\n","model2.add(BatchNormalization())\n","model2.add(Activation(\"gelu\"))\n","\n","# model2.add(Dense(32, kernel_regularizer=regularizers.L2(l2=0.005)))\n","# model2.add(BatchNormalization())\n","# model2.add(Activation(\"gelu\"))\n","\n","model2.add(Dense(16, kernel_regularizer=regularizers.L2(l2=0.005)))\n","model2.add(BatchNormalization())\n","model2.add(Activation(\"gelu\"))\n","\n","model2.add(Dropout(0.2))\n","model2.add(Dense(num_output_features))\n","\n","# optimization options\n","epsilon = 0.001\n","opt = optimizers.Adam(learning_rate=epsilon)\n","\n","# compile the model with the optimization options\n","model2.compile(loss=\"mean_absolute_error\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feVCJJu_-7d-","outputId":"98a741f8-8f6b-481b-b6f4-023e90c80a52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","440/440 [==============================] - 6s 8ms/step - loss: 0.4287 - accuracy: 0.4099 - val_loss: 0.1846 - val_accuracy: 0.5586\n","Epoch 2/50\n","440/440 [==============================] - 4s 9ms/step - loss: 0.1251 - accuracy: 0.5330 - val_loss: 0.0813 - val_accuracy: 0.6139\n","Epoch 3/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0660 - accuracy: 0.6015 - val_loss: 0.0516 - val_accuracy: 0.7834\n","Epoch 4/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0435 - accuracy: 0.7027 - val_loss: 0.0380 - val_accuracy: 0.8346\n","Epoch 5/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0341 - accuracy: 0.7695 - val_loss: 0.0387 - val_accuracy: 0.8219\n","Epoch 6/50\n","440/440 [==============================] - 4s 8ms/step - loss: 0.0312 - accuracy: 0.8066 - val_loss: 0.0193 - val_accuracy: 0.9214\n","Epoch 7/50\n","440/440 [==============================] - 3s 8ms/step - loss: 0.0298 - accuracy: 0.8163 - val_loss: 0.0224 - val_accuracy: 0.8796\n","Epoch 8/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0295 - accuracy: 0.8191 - val_loss: 0.0320 - val_accuracy: 0.8945\n","Epoch 9/50\n","440/440 [==============================] - 3s 7ms/step - loss: 0.0284 - accuracy: 0.8249 - val_loss: 0.0189 - val_accuracy: 0.9036\n","Epoch 10/50\n","440/440 [==============================] - 3s 7ms/step - loss: 0.0281 - accuracy: 0.8280 - val_loss: 0.0254 - val_accuracy: 0.8801\n","Epoch 11/50\n","440/440 [==============================] - 4s 9ms/step - loss: 0.0282 - accuracy: 0.8247 - val_loss: 0.0181 - val_accuracy: 0.9105\n","Epoch 12/50\n","440/440 [==============================] - 3s 7ms/step - loss: 0.0279 - accuracy: 0.8302 - val_loss: 0.0132 - val_accuracy: 0.9313\n","Epoch 13/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8278 - val_loss: 0.0204 - val_accuracy: 0.9030\n","Epoch 14/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.8327 - val_loss: 0.0266 - val_accuracy: 0.8683\n","Epoch 15/50\n","440/440 [==============================] - 4s 8ms/step - loss: 0.0268 - accuracy: 0.8311 - val_loss: 0.0182 - val_accuracy: 0.8508\n","Epoch 16/50\n","440/440 [==============================] - 3s 8ms/step - loss: 0.0271 - accuracy: 0.8322 - val_loss: 0.0202 - val_accuracy: 0.8558\n","Epoch 17/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8292 - val_loss: 0.0197 - val_accuracy: 0.8517\n","Epoch 18/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0265 - accuracy: 0.8340 - val_loss: 0.0132 - val_accuracy: 0.9397\n","Epoch 19/50\n","440/440 [==============================] - 3s 7ms/step - loss: 0.0266 - accuracy: 0.8288 - val_loss: 0.0135 - val_accuracy: 0.8849\n","Epoch 20/50\n","440/440 [==============================] - 4s 9ms/step - loss: 0.0263 - accuracy: 0.8314 - val_loss: 0.0182 - val_accuracy: 0.8753\n","Epoch 21/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0263 - accuracy: 0.8317 - val_loss: 0.0218 - val_accuracy: 0.8664\n","Epoch 22/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0266 - accuracy: 0.8301 - val_loss: 0.0240 - val_accuracy: 0.8842\n","Epoch 23/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0268 - accuracy: 0.8324 - val_loss: 0.0203 - val_accuracy: 0.9082\n","Epoch 24/50\n","440/440 [==============================] - 4s 8ms/step - loss: 0.0263 - accuracy: 0.8312 - val_loss: 0.0126 - val_accuracy: 0.9438\n","Epoch 25/50\n","440/440 [==============================] - 3s 7ms/step - loss: 0.0262 - accuracy: 0.8346 - val_loss: 0.0206 - val_accuracy: 0.8886\n","Epoch 26/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0263 - accuracy: 0.8349 - val_loss: 0.0194 - val_accuracy: 0.9211\n","Epoch 27/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0261 - accuracy: 0.8332 - val_loss: 0.0188 - val_accuracy: 0.9163\n","Epoch 28/50\n","440/440 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.8329 - val_loss: 0.0216 - val_accuracy: 0.8586\n","Epoch 29/50\n","440/440 [==============================] - 4s 9ms/step - loss: 0.0264 - accuracy: 0.8323 - val_loss: 0.0142 - val_accuracy: 0.8973\n","Epoch 30/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0262 - accuracy: 0.8343 - val_loss: 0.0276 - val_accuracy: 0.8353\n","Epoch 31/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0261 - accuracy: 0.8308 - val_loss: 0.0267 - val_accuracy: 0.8334\n","Epoch 32/50\n","440/440 [==============================] - 3s 6ms/step - loss: 0.0262 - accuracy: 0.8324 - val_loss: 0.0217 - val_accuracy: 0.8763\n","Epoch 33/50\n","328/440 [=====================\u003e........] - ETA: 0s - loss: 0.0264 - accuracy: 0.8356"]}],"source":["# MinMaxScaler\n","early_stopping = EarlyStopping(monitor='val_accuracy',patience=10, restore_best_weights=True)\n","# fit the keras model on the dataset store loss and accuracy in history\n","history2 = model2.fit(X_train, Y_train, epochs=50, batch_size=128, validation_data=(X_val, Y_val), callbacks=[early_stopping])\n","predictions = model2.predict(X_val)\n","mae = mean_absolute_error(Y_val, predictions, multioutput='raw_values')\n","print(mae)\n","print(mean(mae))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Onunyq8lnzjl"},"outputs":[],"source":["num_folds = 5\n","\n","KF = KFold(n_splits=num_folds, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":992545,"status":"ok","timestamp":1715297873605,"user":{"displayName":"Muzhaffar Maruf Ibrahim","userId":"13211234798137897760"},"user_tz":-60},"id":"iuenQ_cU_LOh","outputId":"6266a2b2-437f-460e-d54a-dc4fc3d8878d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.20689662 0.         0.02040816]\n"," [0.20689662 0.         0.04081633]\n"," [0.20689662 0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [0.17241385 1.         0.97959199]\n"," [0.17241385 1.         1.        ]\n"," [0.20689662 0.         0.        ]]\n","---------------\n","[[6.29403517e-01 8.59997586e-01 8.24688760e-01 ... 3.87531467e-09\n","  1.88409761e-09 3.60568697e-01]\n"," [6.29434515e-01 8.59378965e-01 8.45341102e-01 ... 4.05598241e-09\n","  2.23389253e-09 3.53224477e-01]\n"," [6.29464710e-01 8.58757103e-01 8.57416345e-01 ... 4.24507255e-09\n","  2.64440597e-09 3.45898109e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [9.50346734e-01 8.20560964e-01 9.47904088e-01 ... 1.68969752e-08\n","  7.06850948e-08 5.09836433e-01]\n"," [9.50383056e-01 8.19531623e-01 9.48399980e-01 ... 1.77265345e-08\n","  7.60719898e-08 5.03610609e-01]\n"," [6.29371700e-01 8.60612941e-01 6.33016145e-01 ... 3.70269467e-09\n","  1.58654193e-09 3.67930573e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 6s 13ms/step - loss: 0.0274 - accuracy: 0.8493 - val_loss: 0.0296 - val_accuracy: 0.3103\n","Epoch 2/50\n","469/469 [==============================] - 7s 15ms/step - loss: 0.0261 - accuracy: 0.8551 - val_loss: 0.0196 - val_accuracy: 0.4972\n","Epoch 3/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0259 - accuracy: 0.8536 - val_loss: 0.0119 - val_accuracy: 0.7691\n","Epoch 4/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0262 - accuracy: 0.8530 - val_loss: 0.0139 - val_accuracy: 0.7298\n","Epoch 5/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0262 - accuracy: 0.8517 - val_loss: 0.0138 - val_accuracy: 0.6410\n","Epoch 6/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0259 - accuracy: 0.8553 - val_loss: 0.0149 - val_accuracy: 0.6405\n","Epoch 7/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0259 - accuracy: 0.8552 - val_loss: 0.0173 - val_accuracy: 0.8426\n","Epoch 8/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8556 - val_loss: 0.0196 - val_accuracy: 0.8675\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0260 - accuracy: 0.8532 - val_loss: 0.0143 - val_accuracy: 0.9044\n","Epoch 10/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0256 - accuracy: 0.8558 - val_loss: 0.0101 - val_accuracy: 0.8647\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8535 - val_loss: 0.0255 - val_accuracy: 0.8496\n","Epoch 12/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8574 - val_loss: 0.0210 - val_accuracy: 0.8957\n","Epoch 13/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8560 - val_loss: 0.0125 - val_accuracy: 0.8112\n","Epoch 14/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0255 - accuracy: 0.8557 - val_loss: 0.0216 - val_accuracy: 0.8699\n","Epoch 15/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8558 - val_loss: 0.0087 - val_accuracy: 0.8249\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8551 - val_loss: 0.0100 - val_accuracy: 0.8865\n","Epoch 17/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8555 - val_loss: 0.0129 - val_accuracy: 0.8447\n","Epoch 18/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0258 - accuracy: 0.8556 - val_loss: 0.0145 - val_accuracy: 0.8665\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8537 - val_loss: 0.0099 - val_accuracy: 0.8686\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8565 - val_loss: 0.0161 - val_accuracy: 0.6351\n","Epoch 21/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8555 - val_loss: 0.0297 - val_accuracy: 0.8307\n","Epoch 22/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0259 - accuracy: 0.8537 - val_loss: 0.0130 - val_accuracy: 0.9244\n","Epoch 23/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8538 - val_loss: 0.0156 - val_accuracy: 0.8939\n","Epoch 24/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8550 - val_loss: 0.0094 - val_accuracy: 0.9404\n","Epoch 25/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8541 - val_loss: 0.0240 - val_accuracy: 0.8659\n","Epoch 26/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0257 - accuracy: 0.8560 - val_loss: 0.0329 - val_accuracy: 0.8267\n","Epoch 27/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0258 - accuracy: 0.8534 - val_loss: 0.0225 - val_accuracy: 0.8649\n","Epoch 28/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0255 - accuracy: 0.8520 - val_loss: 0.0157 - val_accuracy: 0.8163\n","Epoch 29/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0252 - accuracy: 0.8554 - val_loss: 0.0397 - val_accuracy: 0.1519\n","Epoch 30/50\n","469/469 [==============================] - 5s 11ms/step - loss: 0.0254 - accuracy: 0.8568 - val_loss: 0.0330 - val_accuracy: 0.8637\n","Epoch 31/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8529 - val_loss: 0.0117 - val_accuracy: 0.9188\n","Epoch 32/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0255 - accuracy: 0.8551 - val_loss: 0.0148 - val_accuracy: 0.8593\n","Epoch 33/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8570 - val_loss: 0.0237 - val_accuracy: 0.8583\n","Epoch 34/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0256 - accuracy: 0.8562 - val_loss: 0.0196 - val_accuracy: 0.8495\n","Epoch 35/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8584 - val_loss: 0.0197 - val_accuracy: 0.8689\n","Epoch 36/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8581 - val_loss: 0.0243 - val_accuracy: 0.8397\n","Epoch 37/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8541 - val_loss: 0.0343 - val_accuracy: 0.8385\n","Epoch 38/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0255 - accuracy: 0.8548 - val_loss: 0.0394 - val_accuracy: 0.7709\n","Epoch 39/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.8582 - val_loss: 0.0278 - val_accuracy: 0.8671\n","Epoch 40/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8555 - val_loss: 0.0239 - val_accuracy: 0.8735\n","Epoch 41/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0252 - accuracy: 0.8559 - val_loss: 0.0215 - val_accuracy: 0.7807\n","Epoch 42/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0252 - accuracy: 0.8550 - val_loss: 0.0236 - val_accuracy: 0.8747\n","Epoch 43/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0249 - accuracy: 0.8553 - val_loss: 0.0263 - val_accuracy: 0.8745\n","Epoch 44/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0251 - accuracy: 0.8565 - val_loss: 0.0262 - val_accuracy: 0.3695\n","Epoch 45/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0251 - accuracy: 0.8571 - val_loss: 0.0183 - val_accuracy: 0.7935\n","Epoch 46/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.8579 - val_loss: 0.0225 - val_accuracy: 0.8581\n","Epoch 47/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0254 - accuracy: 0.8554 - val_loss: 0.0157 - val_accuracy: 0.9163\n","Epoch 48/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8559 - val_loss: 0.0233 - val_accuracy: 0.8520\n","Epoch 49/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0251 - accuracy: 0.8583 - val_loss: 0.0141 - val_accuracy: 0.7450\n","Epoch 50/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.8544 - val_loss: 0.0117 - val_accuracy: 0.8587\n","469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.20689662 0.         0.02040816]\n"," [0.20689662 0.         0.04081633]\n"," [0.20689662 0.         0.06122447]\n"," ...\n"," [0.37931031 1.         0.97959199]\n"," [0.37931031 1.         1.        ]\n"," [0.41379308 0.         0.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[6.29403517e-01 8.59997586e-01 8.24688760e-01 ... 3.87531467e-09\n","  1.88409761e-09 3.60568697e-01]\n"," [6.29434515e-01 8.59378965e-01 8.45341102e-01 ... 4.05598241e-09\n","  2.23389253e-09 3.53224477e-01]\n"," [6.29464710e-01 8.58757103e-01 8.57416345e-01 ... 4.24507255e-09\n","  2.64440597e-09 3.45898109e-01]\n"," ...\n"," [8.82434825e-01 6.47859770e-01 8.77903860e-01 ... 3.49082965e-05\n","  6.12034610e-05 5.45189994e-01]\n"," [8.82394345e-01 6.46655115e-01 8.78538363e-01 ... 3.62075161e-05\n","  6.45468269e-05 5.38920619e-01]\n"," [4.82396185e-01 6.92766276e-01 4.82571240e-01 ... 6.73465323e-06\n","  2.88261217e-06 4.01927777e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0270 - accuracy: 0.8162 - val_loss: 0.0241 - val_accuracy: 0.9087\n","Epoch 2/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8184 - val_loss: 0.0098 - val_accuracy: 0.9780\n","Epoch 3/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8174 - val_loss: 0.0125 - val_accuracy: 0.9804\n","Epoch 4/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0269 - accuracy: 0.8156 - val_loss: 0.0459 - val_accuracy: 0.9741\n","Epoch 5/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0270 - accuracy: 0.8152 - val_loss: 0.0307 - val_accuracy: 0.9129\n","Epoch 6/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8156 - val_loss: 0.0229 - val_accuracy: 0.9722\n","Epoch 7/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.8150 - val_loss: 0.0228 - val_accuracy: 0.9458\n","Epoch 8/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8159 - val_loss: 0.0229 - val_accuracy: 0.9359\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0270 - accuracy: 0.8185 - val_loss: 0.0172 - val_accuracy: 0.9563\n","Epoch 10/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0268 - accuracy: 0.8141 - val_loss: 0.0462 - val_accuracy: 0.8831\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.8138 - val_loss: 0.0106 - val_accuracy: 0.8954\n","Epoch 12/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8140 - val_loss: 0.0089 - val_accuracy: 0.9307\n","Epoch 13/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0268 - accuracy: 0.8169 - val_loss: 0.0355 - val_accuracy: 0.9281\n","Epoch 14/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0265 - accuracy: 0.8166 - val_loss: 0.0157 - val_accuracy: 0.9576\n","Epoch 15/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8140 - val_loss: 0.0213 - val_accuracy: 0.9814\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0267 - accuracy: 0.8180 - val_loss: 0.0171 - val_accuracy: 0.9723\n","Epoch 17/50\n","469/469 [==============================] - 5s 10ms/step - loss: 0.0267 - accuracy: 0.8189 - val_loss: 0.0179 - val_accuracy: 0.9557\n","Epoch 18/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0268 - accuracy: 0.8150 - val_loss: 0.0147 - val_accuracy: 0.8749\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.8162 - val_loss: 0.0206 - val_accuracy: 0.9604\n","Epoch 20/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0271 - accuracy: 0.8156 - val_loss: 0.0420 - val_accuracy: 0.9624\n","Epoch 21/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0267 - accuracy: 0.8180 - val_loss: 0.0184 - val_accuracy: 0.9348\n","Epoch 22/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0268 - accuracy: 0.8163 - val_loss: 0.0161 - val_accuracy: 0.9735\n","Epoch 23/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.8147 - val_loss: 0.0127 - val_accuracy: 0.8455\n","Epoch 24/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8161 - val_loss: 0.0268 - val_accuracy: 0.9768\n","Epoch 25/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0267 - accuracy: 0.8198 - val_loss: 0.0306 - val_accuracy: 0.9614\n","Epoch 26/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0267 - accuracy: 0.8169 - val_loss: 0.0228 - val_accuracy: 0.9524\n","Epoch 27/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0268 - accuracy: 0.8169 - val_loss: 0.0531 - val_accuracy: 0.9673\n","Epoch 28/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8156 - val_loss: 0.0146 - val_accuracy: 0.8828\n","Epoch 29/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0266 - accuracy: 0.8173 - val_loss: 0.0175 - val_accuracy: 0.9425\n","Epoch 30/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0266 - accuracy: 0.8170 - val_loss: 0.0381 - val_accuracy: 0.8883\n","Epoch 31/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0266 - accuracy: 0.8167 - val_loss: 0.0184 - val_accuracy: 0.9857\n","Epoch 32/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.8163 - val_loss: 0.0251 - val_accuracy: 0.9763\n","Epoch 33/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0268 - accuracy: 0.8128 - val_loss: 0.0293 - val_accuracy: 0.8401\n","Epoch 34/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0266 - accuracy: 0.8183 - val_loss: 0.0213 - val_accuracy: 0.9466\n","Epoch 35/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.8163 - val_loss: 0.0127 - val_accuracy: 0.8817\n","Epoch 36/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8138 - val_loss: 0.0134 - val_accuracy: 0.9191\n","Epoch 37/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0270 - accuracy: 0.8134 - val_loss: 0.0087 - val_accuracy: 0.9391\n","Epoch 38/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0269 - accuracy: 0.8181 - val_loss: 0.0222 - val_accuracy: 0.9498\n","Epoch 39/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0268 - accuracy: 0.8134 - val_loss: 0.0186 - val_accuracy: 0.9595\n","Epoch 40/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.8162 - val_loss: 0.0154 - val_accuracy: 0.9449\n","Epoch 41/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0268 - accuracy: 0.8167 - val_loss: 0.0206 - val_accuracy: 0.9155\n","Epoch 42/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0265 - accuracy: 0.8183 - val_loss: 0.0257 - val_accuracy: 0.9571\n","Epoch 43/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0270 - accuracy: 0.8152 - val_loss: 0.0605 - val_accuracy: 0.6680\n","Epoch 44/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0266 - accuracy: 0.8149 - val_loss: 0.0262 - val_accuracy: 0.9342\n","Epoch 45/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.8176 - val_loss: 0.0156 - val_accuracy: 0.9576\n","Epoch 46/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.8138 - val_loss: 0.0093 - val_accuracy: 0.9482\n","Epoch 47/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0267 - accuracy: 0.8129 - val_loss: 0.0258 - val_accuracy: 0.9807\n","Epoch 48/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0266 - accuracy: 0.8183 - val_loss: 0.0102 - val_accuracy: 0.9429\n","Epoch 49/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.8154 - val_loss: 0.0154 - val_accuracy: 0.9429\n","Epoch 50/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8175 - val_loss: 0.0085 - val_accuracy: 0.9631\n","469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.41379308 0.         0.02040816]\n"," [0.41379308 0.         0.04081633]\n"," [0.41379308 0.         0.06122447]\n"," ...\n"," [0.58620692 1.         0.97959199]\n"," [0.58620692 1.         1.        ]\n"," [0.62068969 0.         0.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[4.82214088e-01 6.91972813e-01 7.30307667e-01 ... 6.97556941e-06\n","  3.28293605e-06 3.94507245e-01]\n"," [4.82034243e-01 6.91180431e-01 7.56771617e-01 ... 7.22510373e-06\n","  3.73424713e-06 3.87104368e-01]\n"," [4.81856620e-01 6.90388998e-01 7.72142730e-01 ... 7.48356453e-06\n","  4.24236561e-06 3.79719147e-01]\n"," ...\n"," [8.06806628e-01 4.51676286e-01 8.00841963e-01 ... 3.90687324e-03\n","  4.00182270e-03 5.83951711e-01]\n"," [8.06689339e-01 4.50296263e-01 8.01615086e-01 ... 4.02386381e-03\n","  4.16791806e-03 5.77639766e-01]\n"," [3.27892978e-01 5.02151225e-01 3.25269750e-01 ... 7.61082795e-04\n","  3.25545334e-04 4.39168350e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0279 - accuracy: 0.8088 - val_loss: 0.0183 - val_accuracy: 0.9472\n","Epoch 2/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0276 - accuracy: 0.8110 - val_loss: 0.0263 - val_accuracy: 0.8966\n","Epoch 3/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0277 - accuracy: 0.8078 - val_loss: 0.0116 - val_accuracy: 0.9245\n","Epoch 4/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8123 - val_loss: 0.0113 - val_accuracy: 0.9754\n","Epoch 5/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0274 - accuracy: 0.8106 - val_loss: 0.0159 - val_accuracy: 0.9775\n","Epoch 6/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8084 - val_loss: 0.0122 - val_accuracy: 0.9052\n","Epoch 7/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8055 - val_loss: 0.0208 - val_accuracy: 0.9436\n","Epoch 8/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0277 - accuracy: 0.8088 - val_loss: 0.0175 - val_accuracy: 0.8935\n","Epoch 9/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0277 - accuracy: 0.8098 - val_loss: 0.0223 - val_accuracy: 0.8953\n","Epoch 10/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8069 - val_loss: 0.0320 - val_accuracy: 0.9495\n","Epoch 11/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8113 - val_loss: 0.0152 - val_accuracy: 0.9151\n","Epoch 12/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8086 - val_loss: 0.0125 - val_accuracy: 0.9413\n","Epoch 13/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0276 - accuracy: 0.8121 - val_loss: 0.0203 - val_accuracy: 0.9465\n","Epoch 14/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8135 - val_loss: 0.0118 - val_accuracy: 0.8882\n","Epoch 15/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8091 - val_loss: 0.0168 - val_accuracy: 0.9896\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0279 - accuracy: 0.8128 - val_loss: 0.0102 - val_accuracy: 0.9707\n","Epoch 17/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0273 - accuracy: 0.8099 - val_loss: 0.0136 - val_accuracy: 0.9525\n","Epoch 18/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0274 - accuracy: 0.8123 - val_loss: 0.0204 - val_accuracy: 0.9767\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8104 - val_loss: 0.0181 - val_accuracy: 0.9676\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0278 - accuracy: 0.8118 - val_loss: 0.0196 - val_accuracy: 0.9654\n","Epoch 21/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0278 - accuracy: 0.8096 - val_loss: 0.0314 - val_accuracy: 0.9594\n","Epoch 22/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0276 - accuracy: 0.8088 - val_loss: 0.0224 - val_accuracy: 0.9525\n","Epoch 23/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8083 - val_loss: 0.0276 - val_accuracy: 0.9676\n","Epoch 24/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0276 - accuracy: 0.8089 - val_loss: 0.0119 - val_accuracy: 0.9671\n","Epoch 25/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0276 - accuracy: 0.8096 - val_loss: 0.0200 - val_accuracy: 0.9681\n","Epoch 26/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0273 - accuracy: 0.8110 - val_loss: 0.0141 - val_accuracy: 0.9153\n","Epoch 27/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.8095 - val_loss: 0.0217 - val_accuracy: 0.9702\n","Epoch 28/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8110 - val_loss: 0.0173 - val_accuracy: 0.9751\n","Epoch 29/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0277 - accuracy: 0.8126 - val_loss: 0.0291 - val_accuracy: 0.9385\n","Epoch 30/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0275 - accuracy: 0.8088 - val_loss: 0.0178 - val_accuracy: 0.9152\n","Epoch 31/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0275 - accuracy: 0.8115 - val_loss: 0.0117 - val_accuracy: 0.9371\n","Epoch 32/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0273 - accuracy: 0.8087 - val_loss: 0.0329 - val_accuracy: 0.9552\n","Epoch 33/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8113 - val_loss: 0.0122 - val_accuracy: 0.9405\n","Epoch 34/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0276 - accuracy: 0.8108 - val_loss: 0.0128 - val_accuracy: 0.9597\n","Epoch 35/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0276 - accuracy: 0.8104 - val_loss: 0.0275 - val_accuracy: 0.9488\n","Epoch 36/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0276 - accuracy: 0.8131 - val_loss: 0.0128 - val_accuracy: 0.9563\n","Epoch 37/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.8098 - val_loss: 0.0176 - val_accuracy: 0.9482\n","Epoch 38/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0278 - accuracy: 0.8160 - val_loss: 0.0116 - val_accuracy: 0.9448\n","Epoch 39/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0274 - accuracy: 0.8114 - val_loss: 0.0116 - val_accuracy: 0.9312\n","Epoch 40/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8079 - val_loss: 0.0144 - val_accuracy: 0.9471\n","Epoch 41/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.8097 - val_loss: 0.0193 - val_accuracy: 0.9641\n","Epoch 42/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8120 - val_loss: 0.0138 - val_accuracy: 0.9687\n","Epoch 43/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0274 - accuracy: 0.8120 - val_loss: 0.0351 - val_accuracy: 0.9647\n","Epoch 44/50\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0276 - accuracy: 0.8100 - val_loss: 0.0213 - val_accuracy: 0.8969\n","Epoch 45/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0276 - accuracy: 0.8108 - val_loss: 0.0300 - val_accuracy: 0.9623\n","Epoch 46/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - accuracy: 0.8084 - val_loss: 0.0096 - val_accuracy: 0.9426\n","Epoch 47/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0275 - accuracy: 0.8123 - val_loss: 0.0110 - val_accuracy: 0.9705\n","Epoch 48/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0276 - accuracy: 0.8079 - val_loss: 0.0192 - val_accuracy: 0.9263\n","Epoch 49/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0276 - accuracy: 0.8081 - val_loss: 0.0114 - val_accuracy: 0.9678\n","Epoch 50/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.8108 - val_loss: 0.0207 - val_accuracy: 0.8987\n","469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.62068969 0.         0.02040816]\n"," [0.62068969 0.         0.04081633]\n"," [0.62068969 0.         0.06122447]\n"," ...\n"," [0.79310338 1.         0.97959199]\n"," [0.79310338 1.         1.        ]\n"," [0.82758615 0.         0.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[3.27497017e-01 5.01179656e-01 6.29070035e-01 ... 7.83152938e-04\n","  3.61110546e-04 4.31688376e-01]\n"," [3.27106323e-01 5.00213487e-01 6.61345594e-01 ... 8.05863079e-04\n","  4.00158850e-04 4.24226255e-01]\n"," [3.26720896e-01 4.99252507e-01 6.80012578e-01 ... 8.29231747e-04\n","  4.42984165e-04 4.16781789e-01]\n"," ...\n"," [7.24390581e-01 2.35548531e-01 7.17725261e-01 ... 9.63018190e-02\n","  6.84704349e-02 6.26204959e-01]\n"," [7.24196490e-01 2.33993140e-01 7.18636994e-01 ... 9.87125675e-02\n","  7.07083461e-02 6.19852013e-01]\n"," [1.66719356e-01 2.92038477e-01 1.62046248e-01 ... 1.96444643e-02\n","  8.39884160e-03 4.79721148e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0260 - accuracy: 0.8240 - val_loss: 0.0178 - val_accuracy: 0.9560\n","Epoch 2/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0258 - accuracy: 0.8283 - val_loss: 0.0145 - val_accuracy: 0.8604\n","Epoch 3/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8296 - val_loss: 0.0126 - val_accuracy: 0.9083\n","Epoch 4/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8299 - val_loss: 0.0134 - val_accuracy: 0.9186\n","Epoch 5/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8315 - val_loss: 0.0244 - val_accuracy: 0.8965\n","Epoch 6/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0255 - accuracy: 0.8306 - val_loss: 0.0160 - val_accuracy: 0.9344\n","Epoch 7/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8309 - val_loss: 0.0174 - val_accuracy: 0.9225\n","Epoch 8/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8291 - val_loss: 0.0225 - val_accuracy: 0.8759\n","Epoch 9/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8293 - val_loss: 0.0141 - val_accuracy: 0.9443\n","Epoch 10/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0256 - accuracy: 0.8318 - val_loss: 0.0243 - val_accuracy: 0.7454\n","Epoch 11/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0256 - accuracy: 0.8285 - val_loss: 0.0163 - val_accuracy: 0.9423\n","Epoch 12/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8330 - val_loss: 0.0155 - val_accuracy: 0.9549\n","Epoch 13/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8320 - val_loss: 0.0161 - val_accuracy: 0.8052\n","Epoch 14/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8300 - val_loss: 0.0345 - val_accuracy: 0.9216\n","Epoch 15/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0257 - accuracy: 0.8287 - val_loss: 0.0144 - val_accuracy: 0.9639\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0255 - accuracy: 0.8297 - val_loss: 0.0149 - val_accuracy: 0.9091\n","Epoch 17/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8298 - val_loss: 0.0178 - val_accuracy: 0.9500\n","Epoch 18/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8340 - val_loss: 0.0151 - val_accuracy: 0.9607\n","Epoch 19/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0257 - accuracy: 0.8295 - val_loss: 0.0178 - val_accuracy: 0.9287\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.8325 - val_loss: 0.0149 - val_accuracy: 0.9497\n","Epoch 21/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0259 - accuracy: 0.8302 - val_loss: 0.0178 - val_accuracy: 0.9195\n","Epoch 22/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8295 - val_loss: 0.0139 - val_accuracy: 0.8565\n","Epoch 23/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0258 - accuracy: 0.8272 - val_loss: 0.0114 - val_accuracy: 0.9221\n","Epoch 24/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8305 - val_loss: 0.0354 - val_accuracy: 0.9153\n","Epoch 25/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0257 - accuracy: 0.8288 - val_loss: 0.0204 - val_accuracy: 0.8898\n","Epoch 26/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8294 - val_loss: 0.0220 - val_accuracy: 0.9149\n","Epoch 27/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0256 - accuracy: 0.8312 - val_loss: 0.0288 - val_accuracy: 0.8701\n","Epoch 28/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8309 - val_loss: 0.0308 - val_accuracy: 0.8823\n","Epoch 29/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8324 - val_loss: 0.0254 - val_accuracy: 0.8470\n","Epoch 30/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8294 - val_loss: 0.0215 - val_accuracy: 0.9185\n","Epoch 31/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0256 - accuracy: 0.8316 - val_loss: 0.0171 - val_accuracy: 0.9222\n","Epoch 32/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0253 - accuracy: 0.8324 - val_loss: 0.0152 - val_accuracy: 0.8600\n","Epoch 33/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8299 - val_loss: 0.0167 - val_accuracy: 0.8457\n","Epoch 34/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8290 - val_loss: 0.0176 - val_accuracy: 0.9449\n","Epoch 35/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0257 - accuracy: 0.8288 - val_loss: 0.0162 - val_accuracy: 0.9458\n","Epoch 36/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0257 - accuracy: 0.8291 - val_loss: 0.0202 - val_accuracy: 0.8896\n","Epoch 37/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8282 - val_loss: 0.0246 - val_accuracy: 0.9050\n","Epoch 38/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.8287 - val_loss: 0.0205 - val_accuracy: 0.9098\n","Epoch 39/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8314 - val_loss: 0.0129 - val_accuracy: 0.9692\n","Epoch 40/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0256 - accuracy: 0.8284 - val_loss: 0.0177 - val_accuracy: 0.8709\n","Epoch 41/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8307 - val_loss: 0.0140 - val_accuracy: 0.9238\n","Epoch 42/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8300 - val_loss: 0.0247 - val_accuracy: 0.8896\n","Epoch 43/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0258 - accuracy: 0.8300 - val_loss: 0.0346 - val_accuracy: 0.8652\n","Epoch 44/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0257 - accuracy: 0.8286 - val_loss: 0.0148 - val_accuracy: 0.9176\n","Epoch 45/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8340 - val_loss: 0.0157 - val_accuracy: 0.8877\n","Epoch 46/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.8329 - val_loss: 0.0183 - val_accuracy: 0.8802\n","Epoch 47/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.8323 - val_loss: 0.0167 - val_accuracy: 0.9569\n","Epoch 48/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0258 - accuracy: 0.8308 - val_loss: 0.0156 - val_accuracy: 0.9221\n","Epoch 49/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8318 - val_loss: 0.0164 - val_accuracy: 0.9421\n","Epoch 50/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0258 - accuracy: 0.8309 - val_loss: 0.0143 - val_accuracy: 0.9610\n","469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [0.79310338 1.         0.97959199]\n"," [0.79310338 1.         1.        ]\n"," [0.82758615 0.         0.        ]]\n","***************\n","[[0.82758615 0.         0.02040816]\n"," [0.82758615 0.         0.04081633]\n"," [0.82758615 0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [7.24390581e-01 2.35548531e-01 7.17725261e-01 ... 9.63018190e-02\n","  6.84704349e-02 6.26204959e-01]\n"," [7.24196490e-01 2.33993140e-01 7.18636994e-01 ... 9.87125675e-02\n","  7.07083461e-02 6.19852013e-01]\n"," [1.66719356e-01 2.92038477e-01 1.62046248e-01 ... 1.96444643e-02\n","  8.39884160e-03 4.79721148e-01]]\n","***************\n","[[0.16610945 0.2908888  0.52191034 ... 0.02012312 0.00914906 0.47218173]\n"," [0.16550789 0.28974884 0.55999749 ... 0.02061343 0.00995784 0.46466017]\n"," [0.16491459 0.28861832 0.58196034 ... 0.0211157  0.01082892 0.45715646]\n"," ...\n"," [0.636063   0.00342996 0.62825995 ... 0.95835936 0.52032637 0.67847551]\n"," [0.63578789 0.00173076 0.62932962 ... 0.97895847 0.53443718 0.67206548]\n"," [0.635517   0.         0.63037997 ... 1.         0.5485187  0.6656735 ]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0179 - accuracy: 0.8622 - val_loss: 0.0897 - val_accuracy: 0.7619\n","Epoch 2/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0163 - accuracy: 0.8631 - val_loss: 0.1064 - val_accuracy: 0.5636\n","Epoch 3/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0162 - accuracy: 0.8642 - val_loss: 0.1247 - val_accuracy: 0.6157\n","Epoch 4/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0162 - accuracy: 0.8649 - val_loss: 0.1068 - val_accuracy: 0.5469\n","Epoch 5/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0162 - accuracy: 0.8663 - val_loss: 0.1028 - val_accuracy: 0.7296\n","Epoch 6/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.8706 - val_loss: 0.0894 - val_accuracy: 0.6662\n","Epoch 7/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.8696 - val_loss: 0.1097 - val_accuracy: 0.6210\n","Epoch 8/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0160 - accuracy: 0.8680 - val_loss: 0.0855 - val_accuracy: 0.7137\n","Epoch 9/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8688 - val_loss: 0.1238 - val_accuracy: 0.6743\n","Epoch 10/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8692 - val_loss: 0.1125 - val_accuracy: 0.7388\n","Epoch 11/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8651 - val_loss: 0.1081 - val_accuracy: 0.6694\n","Epoch 12/50\n","469/469 [==============================] - 5s 10ms/step - loss: 0.0158 - accuracy: 0.8668 - val_loss: 0.0933 - val_accuracy: 0.6842\n","Epoch 13/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8709 - val_loss: 0.1227 - val_accuracy: 0.5970\n","Epoch 14/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8712 - val_loss: 0.1022 - val_accuracy: 0.5842\n","Epoch 15/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8695 - val_loss: 0.0940 - val_accuracy: 0.5711\n","Epoch 16/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0158 - accuracy: 0.8673 - val_loss: 0.1039 - val_accuracy: 0.6414\n","Epoch 17/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8664 - val_loss: 0.0906 - val_accuracy: 0.5862\n","Epoch 18/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8649 - val_loss: 0.1315 - val_accuracy: 0.6055\n","Epoch 19/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8685 - val_loss: 0.1148 - val_accuracy: 0.6334\n","Epoch 20/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0158 - accuracy: 0.8690 - val_loss: 0.1312 - val_accuracy: 0.4393\n","Epoch 21/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8693 - val_loss: 0.1171 - val_accuracy: 0.4639\n","Epoch 22/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.8714 - val_loss: 0.0916 - val_accuracy: 0.6304\n","Epoch 23/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8655 - val_loss: 0.0900 - val_accuracy: 0.5830\n","Epoch 24/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0158 - accuracy: 0.8724 - val_loss: 0.1003 - val_accuracy: 0.6508\n","Epoch 25/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0157 - accuracy: 0.8711 - val_loss: 0.1168 - val_accuracy: 0.7054\n","Epoch 26/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8680 - val_loss: 0.1482 - val_accuracy: 0.4754\n","Epoch 27/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8683 - val_loss: 0.1197 - val_accuracy: 0.5660\n","Epoch 28/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0159 - accuracy: 0.8690 - val_loss: 0.1153 - val_accuracy: 0.5734\n","Epoch 29/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0157 - accuracy: 0.8702 - val_loss: 0.0818 - val_accuracy: 0.7693\n","Epoch 30/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8675 - val_loss: 0.0993 - val_accuracy: 0.5855\n","Epoch 31/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8697 - val_loss: 0.1364 - val_accuracy: 0.4732\n","Epoch 32/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0160 - accuracy: 0.8688 - val_loss: 0.1235 - val_accuracy: 0.4676\n","Epoch 33/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0158 - accuracy: 0.8696 - val_loss: 0.0883 - val_accuracy: 0.6482\n","Epoch 34/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8686 - val_loss: 0.0905 - val_accuracy: 0.6952\n","Epoch 35/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.8687 - val_loss: 0.1094 - val_accuracy: 0.5452\n","Epoch 36/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8680 - val_loss: 0.0832 - val_accuracy: 0.7065\n","Epoch 37/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0159 - accuracy: 0.8704 - val_loss: 0.1112 - val_accuracy: 0.7490\n","Epoch 38/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8698 - val_loss: 0.1109 - val_accuracy: 0.7061\n","Epoch 39/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8690 - val_loss: 0.1080 - val_accuracy: 0.6452\n","Epoch 40/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8691 - val_loss: 0.0988 - val_accuracy: 0.7199\n","Epoch 41/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0158 - accuracy: 0.8701 - val_loss: 0.0995 - val_accuracy: 0.7711\n","Epoch 42/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8675 - val_loss: 0.0947 - val_accuracy: 0.6547\n","Epoch 43/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8698 - val_loss: 0.0943 - val_accuracy: 0.7044\n","Epoch 44/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.8673 - val_loss: 0.1136 - val_accuracy: 0.5668\n","Epoch 45/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0159 - accuracy: 0.8687 - val_loss: 0.0973 - val_accuracy: 0.6613\n","Epoch 46/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8667 - val_loss: 0.1242 - val_accuracy: 0.4797\n","Epoch 47/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8712 - val_loss: 0.1157 - val_accuracy: 0.7244\n","Epoch 48/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8702 - val_loss: 0.0970 - val_accuracy: 0.6250\n","Epoch 49/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0158 - accuracy: 0.8701 - val_loss: 0.1240 - val_accuracy: 0.5376\n","Epoch 50/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8681 - val_loss: 0.1276 - val_accuracy: 0.6410\n","469/469 [==============================] - 1s 2ms/step\n","[array([0.01312058, 0.02493389, 0.01254628, 0.00695052, 0.00200011,\n","       0.00180076, 0.01487795]), array([0.00961793, 0.00765359, 0.01241458, 0.00098372, 0.00162539,\n","       0.00174032, 0.01934876]), array([0.03706091, 0.05517017, 0.03044206, 0.0009669 , 0.00313538,\n","       0.00209356, 0.01018352]), array([0.01614998, 0.00677888, 0.01609848, 0.02101178, 0.01089345,\n","       0.00561581, 0.01748961]), array([0.09265981, 0.18989401, 0.09852358, 0.21574388, 0.1430635 ,\n","       0.12384343, 0.02563591])]\n"]}],"source":["mae_scores = []\n","early_stopping = EarlyStopping(monitor='val_accuracy',patience=10, restore_best_weights=True)\n","for train_index, test_index in KF.split(Input):\n","  X_train, X_val = Input[train_index], Input[test_index]\n","  Y_train, Y_val = Output[train_index], Output[test_index]\n","  print(X_train)\n","  print('***************')\n","  print(X_val)\n","  print('---------------')\n","  print(Y_train)\n","  print('***************')\n","  print(Y_val)\n","  print('===============')\n","  history2 = model2.fit(X_train, Y_train, epochs=50, batch_size=128, validation_data=(X_val, Y_val))#, callbacks=[early_stopping])\n","  predictions = model2.predict(X_val)\n","  mae = mean_absolute_error(Y_val, predictions, multioutput='raw_values')\n","  mae_scores.append(mae)\n","print(mae_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"HIy_KojcFd-v"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.20689662 0.         0.02040816]\n"," [0.20689662 0.         0.04081633]\n"," [0.20689662 0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [0.17241385 1.         0.97959199]\n"," [0.17241385 1.         1.        ]\n"," [0.20689662 0.         0.        ]]\n","---------------\n","[[6.29403517e-01 8.59997586e-01 8.24688760e-01 ... 3.87531467e-09\n","  1.88409761e-09 3.60568697e-01]\n"," [6.29434515e-01 8.59378965e-01 8.45341102e-01 ... 4.05598241e-09\n","  2.23389253e-09 3.53224477e-01]\n"," [6.29464710e-01 8.58757103e-01 8.57416345e-01 ... 4.24507255e-09\n","  2.64440597e-09 3.45898109e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [9.50346734e-01 8.20560964e-01 9.47904088e-01 ... 1.68969752e-08\n","  7.06850948e-08 5.09836433e-01]\n"," [9.50383056e-01 8.19531623e-01 9.48399980e-01 ... 1.77265345e-08\n","  7.60719898e-08 5.03610609e-01]\n"," [6.29371700e-01 8.60612941e-01 6.33016145e-01 ... 3.70269467e-09\n","  1.58654193e-09 3.67930573e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0306 - accuracy: 0.8546 - val_loss: 0.0279 - val_accuracy: 0.3617\n","Epoch 2/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0266 - accuracy: 0.8601 - val_loss: 0.0161 - val_accuracy: 0.8176\n","Epoch 3/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0262 - accuracy: 0.8581 - val_loss: 0.0227 - val_accuracy: 0.8269\n","Epoch 4/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0257 - accuracy: 0.8627 - val_loss: 0.0465 - val_accuracy: 0.8645\n","Epoch 5/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.8630 - val_loss: 0.0314 - val_accuracy: 0.8603\n","Epoch 6/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.8598 - val_loss: 0.0326 - val_accuracy: 0.7836\n","Epoch 7/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8643 - val_loss: 0.0248 - val_accuracy: 0.8051\n","Epoch 8/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0257 - accuracy: 0.8631 - val_loss: 0.0130 - val_accuracy: 0.7942\n","Epoch 9/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - accuracy: 0.8618 - val_loss: 0.0340 - val_accuracy: 0.8225\n","Epoch 10/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0254 - accuracy: 0.8614 - val_loss: 0.0356 - val_accuracy: 0.8648\n","Epoch 11/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0256 - accuracy: 0.8610 - val_loss: 0.0365 - val_accuracy: 0.7797\n","Epoch 12/50\n","469/469 [==============================] - 5s 11ms/step - loss: 0.0257 - accuracy: 0.8635 - val_loss: 0.0138 - val_accuracy: 0.8617\n","Epoch 13/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0256 - accuracy: 0.8618 - val_loss: 0.0157 - val_accuracy: 0.8605\n","Epoch 14/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.8635 - val_loss: 0.0213 - val_accuracy: 0.8152\n","Epoch 15/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8631 - val_loss: 0.0146 - val_accuracy: 0.7373\n","Epoch 16/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0252 - accuracy: 0.8640 - val_loss: 0.0418 - val_accuracy: 0.1677\n","Epoch 17/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0254 - accuracy: 0.8606 - val_loss: 0.0204 - val_accuracy: 0.7073\n","Epoch 18/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.8606 - val_loss: 0.0182 - val_accuracy: 0.7498\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0254 - accuracy: 0.8611 - val_loss: 0.0486 - val_accuracy: 0.8065\n","Epoch 20/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0254 - accuracy: 0.8642 - val_loss: 0.0172 - val_accuracy: 0.8823\n","Epoch 21/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8608 - val_loss: 0.0192 - val_accuracy: 0.9022\n","Epoch 22/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8605 - val_loss: 0.0203 - val_accuracy: 0.8543\n","Epoch 23/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0254 - accuracy: 0.8615 - val_loss: 0.0238 - val_accuracy: 0.7982\n","Epoch 24/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0255 - accuracy: 0.8614 - val_loss: 0.0725 - val_accuracy: 0.5981\n","Epoch 25/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0253 - accuracy: 0.8619 - val_loss: 0.0342 - val_accuracy: 0.7143\n","Epoch 26/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0253 - accuracy: 0.8610 - val_loss: 0.0265 - val_accuracy: 0.7713\n","Epoch 27/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.8607 - val_loss: 0.0332 - val_accuracy: 0.7626\n","Epoch 28/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0255 - accuracy: 0.8612 - val_loss: 0.0211 - val_accuracy: 0.7955\n","Epoch 29/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0254 - accuracy: 0.8606 - val_loss: 0.0437 - val_accuracy: 0.8219\n","Epoch 30/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0254 - accuracy: 0.8616 - val_loss: 0.0264 - val_accuracy: 0.7901\n","Epoch 31/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0252 - accuracy: 0.8602 - val_loss: 0.0488 - val_accuracy: 0.7659\n","Model saved for fold 0 at model_fold_0.h5\n"," 61/469 [==\u003e...........................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.20689662 0.         0.02040816]\n"," [0.20689662 0.         0.04081633]\n"," [0.20689662 0.         0.06122447]\n"," ...\n"," [0.37931031 1.         0.97959199]\n"," [0.37931031 1.         1.        ]\n"," [0.41379308 0.         0.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[6.29403517e-01 8.59997586e-01 8.24688760e-01 ... 3.87531467e-09\n","  1.88409761e-09 3.60568697e-01]\n"," [6.29434515e-01 8.59378965e-01 8.45341102e-01 ... 4.05598241e-09\n","  2.23389253e-09 3.53224477e-01]\n"," [6.29464710e-01 8.58757103e-01 8.57416345e-01 ... 4.24507255e-09\n","  2.64440597e-09 3.45898109e-01]\n"," ...\n"," [8.82434825e-01 6.47859770e-01 8.77903860e-01 ... 3.49082965e-05\n","  6.12034610e-05 5.45189994e-01]\n"," [8.82394345e-01 6.46655115e-01 8.78538363e-01 ... 3.62075161e-05\n","  6.45468269e-05 5.38920619e-01]\n"," [4.82396185e-01 6.92766276e-01 4.82571240e-01 ... 6.73465323e-06\n","  2.88261217e-06 4.01927777e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0273 - accuracy: 0.8195 - val_loss: 0.0361 - val_accuracy: 0.8350\n","Epoch 2/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0271 - accuracy: 0.8260 - val_loss: 0.0572 - val_accuracy: 0.7746\n","Epoch 3/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0272 - accuracy: 0.8254 - val_loss: 0.0279 - val_accuracy: 0.9457\n","Epoch 4/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0274 - accuracy: 0.8253 - val_loss: 0.0270 - val_accuracy: 0.9653\n","Epoch 5/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0273 - accuracy: 0.8237 - val_loss: 0.0119 - val_accuracy: 0.9388\n","Epoch 6/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0271 - accuracy: 0.8231 - val_loss: 0.0229 - val_accuracy: 0.8496\n","Epoch 7/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0268 - accuracy: 0.8243 - val_loss: 0.0186 - val_accuracy: 0.8915\n","Epoch 8/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0270 - accuracy: 0.8199 - val_loss: 0.0229 - val_accuracy: 0.9449\n","Epoch 9/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0273 - accuracy: 0.8211 - val_loss: 0.0278 - val_accuracy: 0.9279\n","Epoch 10/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0272 - accuracy: 0.8219 - val_loss: 0.0247 - val_accuracy: 0.9190\n","Epoch 11/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0270 - accuracy: 0.8219 - val_loss: 0.0206 - val_accuracy: 0.9490\n","Epoch 12/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8255 - val_loss: 0.0125 - val_accuracy: 0.9882\n","Epoch 13/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0273 - accuracy: 0.8219 - val_loss: 0.0141 - val_accuracy: 0.9636\n","Epoch 14/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0271 - accuracy: 0.8249 - val_loss: 0.0563 - val_accuracy: 0.8406\n","Epoch 15/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0272 - accuracy: 0.8230 - val_loss: 0.0278 - val_accuracy: 0.9501\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8226 - val_loss: 0.0294 - val_accuracy: 0.9692\n","Epoch 17/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0273 - accuracy: 0.8205 - val_loss: 0.0126 - val_accuracy: 0.9426\n","Epoch 18/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0271 - accuracy: 0.8228 - val_loss: 0.0257 - val_accuracy: 0.8218\n","Epoch 19/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0272 - accuracy: 0.8209 - val_loss: 0.0088 - val_accuracy: 0.9448\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.8252 - val_loss: 0.0349 - val_accuracy: 0.9724\n","Epoch 21/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.8245 - val_loss: 0.0106 - val_accuracy: 0.9197\n","Epoch 22/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.8247 - val_loss: 0.0155 - val_accuracy: 0.9407\n","Model saved for fold 0 at model_fold_0.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.41379308 0.         0.02040816]\n"," [0.41379308 0.         0.04081633]\n"," [0.41379308 0.         0.06122447]\n"," ...\n"," [0.58620692 1.         0.97959199]\n"," [0.58620692 1.         1.        ]\n"," [0.62068969 0.         0.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[4.82214088e-01 6.91972813e-01 7.30307667e-01 ... 6.97556941e-06\n","  3.28293605e-06 3.94507245e-01]\n"," [4.82034243e-01 6.91180431e-01 7.56771617e-01 ... 7.22510373e-06\n","  3.73424713e-06 3.87104368e-01]\n"," [4.81856620e-01 6.90388998e-01 7.72142730e-01 ... 7.48356453e-06\n","  4.24236561e-06 3.79719147e-01]\n"," ...\n"," [8.06806628e-01 4.51676286e-01 8.00841963e-01 ... 3.90687324e-03\n","  4.00182270e-03 5.83951711e-01]\n"," [8.06689339e-01 4.50296263e-01 8.01615086e-01 ... 4.02386381e-03\n","  4.16791806e-03 5.77639766e-01]\n"," [3.27892978e-01 5.02151225e-01 3.25269750e-01 ... 7.61082795e-04\n","  3.25545334e-04 4.39168350e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0282 - accuracy: 0.8229 - val_loss: 0.0265 - val_accuracy: 0.9213\n","Epoch 2/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0280 - accuracy: 0.8223 - val_loss: 0.0279 - val_accuracy: 0.9818\n","Epoch 3/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0282 - accuracy: 0.8186 - val_loss: 0.0254 - val_accuracy: 0.9321\n","Epoch 4/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0282 - accuracy: 0.8166 - val_loss: 0.0279 - val_accuracy: 0.8561\n","Epoch 5/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0280 - accuracy: 0.8204 - val_loss: 0.0205 - val_accuracy: 0.9667\n","Epoch 6/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0278 - accuracy: 0.8200 - val_loss: 0.0220 - val_accuracy: 0.9060\n","Epoch 7/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0279 - accuracy: 0.8183 - val_loss: 0.0111 - val_accuracy: 0.9390\n","Epoch 8/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0280 - accuracy: 0.8203 - val_loss: 0.0221 - val_accuracy: 0.8599\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0280 - accuracy: 0.8174 - val_loss: 0.0164 - val_accuracy: 0.9739\n","Epoch 10/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0278 - accuracy: 0.8196 - val_loss: 0.0284 - val_accuracy: 0.8282\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0278 - accuracy: 0.8204 - val_loss: 0.0243 - val_accuracy: 0.8927\n","Epoch 12/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0280 - accuracy: 0.8195 - val_loss: 0.0266 - val_accuracy: 0.8694\n","Model saved for fold 0 at model_fold_0.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["469/469 [==============================] - 1s 3ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","***************\n","[[0.62068969 0.         0.02040816]\n"," [0.62068969 0.         0.04081633]\n"," [0.62068969 0.         0.06122447]\n"," ...\n"," [0.79310338 1.         0.97959199]\n"," [0.79310338 1.         1.        ]\n"," [0.82758615 0.         0.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [6.36063001e-01 3.42995869e-03 6.28259952e-01 ... 9.58359362e-01\n","  5.20326367e-01 6.78475513e-01]\n"," [6.35787894e-01 1.73075902e-03 6.29329621e-01 ... 9.78958473e-01\n","  5.34437182e-01 6.72065480e-01]\n"," [6.35517001e-01 0.00000000e+00 6.30379974e-01 ... 1.00000000e+00\n","  5.48518704e-01 6.65673496e-01]]\n","***************\n","[[3.27497017e-01 5.01179656e-01 6.29070035e-01 ... 7.83152938e-04\n","  3.61110546e-04 4.31688376e-01]\n"," [3.27106323e-01 5.00213487e-01 6.61345594e-01 ... 8.05863079e-04\n","  4.00158850e-04 4.24226255e-01]\n"," [3.26720896e-01 4.99252507e-01 6.80012578e-01 ... 8.29231747e-04\n","  4.42984165e-04 4.16781789e-01]\n"," ...\n"," [7.24390581e-01 2.35548531e-01 7.17725261e-01 ... 9.63018190e-02\n","  6.84704349e-02 6.26204959e-01]\n"," [7.24196490e-01 2.33993140e-01 7.18636994e-01 ... 9.87125675e-02\n","  7.07083461e-02 6.19852013e-01]\n"," [1.66719356e-01 2.92038477e-01 1.62046248e-01 ... 1.96444643e-02\n","  8.39884160e-03 4.79721148e-01]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0264 - accuracy: 0.8334 - val_loss: 0.0152 - val_accuracy: 0.9077\n","Epoch 2/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0262 - accuracy: 0.8316 - val_loss: 0.0193 - val_accuracy: 0.8823\n","Epoch 3/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0261 - accuracy: 0.8346 - val_loss: 0.0199 - val_accuracy: 0.9229\n","Epoch 4/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0262 - accuracy: 0.8357 - val_loss: 0.0140 - val_accuracy: 0.8770\n","Epoch 5/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0258 - accuracy: 0.8379 - val_loss: 0.0294 - val_accuracy: 0.8457\n","Epoch 6/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8373 - val_loss: 0.0307 - val_accuracy: 0.8157\n","Epoch 7/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.8355 - val_loss: 0.0238 - val_accuracy: 0.9272\n","Epoch 8/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0261 - accuracy: 0.8382 - val_loss: 0.0239 - val_accuracy: 0.8712\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0260 - accuracy: 0.8327 - val_loss: 0.0156 - val_accuracy: 0.9205\n","Epoch 10/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8389 - val_loss: 0.0268 - val_accuracy: 0.9281\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8390 - val_loss: 0.0184 - val_accuracy: 0.8617\n","Epoch 12/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0260 - accuracy: 0.8376 - val_loss: 0.0154 - val_accuracy: 0.8869\n","Epoch 13/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0262 - accuracy: 0.8356 - val_loss: 0.0412 - val_accuracy: 0.8821\n","Epoch 14/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.8357 - val_loss: 0.0233 - val_accuracy: 0.9715\n","Epoch 15/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.8391 - val_loss: 0.0225 - val_accuracy: 0.9111\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8340 - val_loss: 0.0380 - val_accuracy: 0.8336\n","Epoch 17/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0259 - accuracy: 0.8398 - val_loss: 0.0167 - val_accuracy: 0.9507\n","Epoch 18/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8382 - val_loss: 0.0199 - val_accuracy: 0.9248\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8364 - val_loss: 0.0316 - val_accuracy: 0.7903\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0261 - accuracy: 0.8395 - val_loss: 0.0267 - val_accuracy: 0.8445\n","Epoch 21/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0258 - accuracy: 0.8381 - val_loss: 0.0253 - val_accuracy: 0.8419\n","Epoch 22/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0258 - accuracy: 0.8370 - val_loss: 0.0293 - val_accuracy: 0.9331\n","Epoch 23/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8383 - val_loss: 0.0124 - val_accuracy: 0.8669\n","Epoch 24/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0259 - accuracy: 0.8350 - val_loss: 0.0141 - val_accuracy: 0.8587\n","Model saved for fold 0 at model_fold_0.h5\n"," 62/469 [==\u003e...........................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["469/469 [==============================] - 1s 2ms/step\n","[[0.         0.         0.02040816]\n"," [0.         0.         0.04081633]\n"," [0.         0.         0.06122447]\n"," ...\n"," [0.79310338 1.         0.97959199]\n"," [0.79310338 1.         1.        ]\n"," [0.82758615 0.         0.        ]]\n","***************\n","[[0.82758615 0.         0.02040816]\n"," [0.82758615 0.         0.04081633]\n"," [0.82758615 0.         0.06122447]\n"," ...\n"," [1.         1.         0.95918364]\n"," [1.         1.         0.97959199]\n"," [1.         1.         1.        ]]\n","---------------\n","[[7.67588057e-01 9.99853873e-01 9.10629325e-01 ... 1.85743647e-16\n","  4.77462260e-16 3.29887250e-01]\n"," [7.67829905e-01 9.99409039e-01 9.25470066e-01 ... 4.66488822e-16\n","  1.08325610e-15 3.22599921e-01]\n"," [7.68067912e-01 9.98956724e-01 9.34249438e-01 ... 7.65985415e-16\n","  1.85023832e-15 3.15330248e-01]\n"," ...\n"," [7.24390581e-01 2.35548531e-01 7.17725261e-01 ... 9.63018190e-02\n","  6.84704349e-02 6.26204959e-01]\n"," [7.24196490e-01 2.33993140e-01 7.18636994e-01 ... 9.87125675e-02\n","  7.07083461e-02 6.19852013e-01]\n"," [1.66719356e-01 2.92038477e-01 1.62046248e-01 ... 1.96444643e-02\n","  8.39884160e-03 4.79721148e-01]]\n","***************\n","[[0.16610945 0.2908888  0.52191034 ... 0.02012312 0.00914906 0.47218173]\n"," [0.16550789 0.28974884 0.55999749 ... 0.02061343 0.00995784 0.46466017]\n"," [0.16491459 0.28861832 0.58196034 ... 0.0211157  0.01082892 0.45715646]\n"," ...\n"," [0.636063   0.00342996 0.62825995 ... 0.95835936 0.52032637 0.67847551]\n"," [0.63578789 0.00173076 0.62932962 ... 0.97895847 0.53443718 0.67206548]\n"," [0.635517   0.         0.63037997 ... 1.         0.5485187  0.6656735 ]]\n","===============\n","Epoch 1/50\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0182 - accuracy: 0.8676 - val_loss: 0.1368 - val_accuracy: 0.6464\n","Epoch 2/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.8722 - val_loss: 0.0972 - val_accuracy: 0.6576\n","Epoch 3/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0161 - accuracy: 0.8675 - val_loss: 0.1011 - val_accuracy: 0.6984\n","Epoch 4/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8700 - val_loss: 0.0987 - val_accuracy: 0.6949\n","Epoch 5/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0159 - accuracy: 0.8673 - val_loss: 0.1510 - val_accuracy: 0.4259\n","Epoch 6/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8694 - val_loss: 0.1161 - val_accuracy: 0.6376\n","Epoch 7/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.8691 - val_loss: 0.1200 - val_accuracy: 0.5450\n","Epoch 8/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8693 - val_loss: 0.1010 - val_accuracy: 0.7015\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0157 - accuracy: 0.8706 - val_loss: 0.1414 - val_accuracy: 0.6362\n","Epoch 10/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8691 - val_loss: 0.1415 - val_accuracy: 0.5009\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.8693 - val_loss: 0.1322 - val_accuracy: 0.5459\n","Epoch 12/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.8703 - val_loss: 0.1175 - val_accuracy: 0.7014\n","Epoch 13/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.8701 - val_loss: 0.1055 - val_accuracy: 0.7403\n","Epoch 14/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0159 - accuracy: 0.8698 - val_loss: 0.1237 - val_accuracy: 0.6959\n","Epoch 15/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8687 - val_loss: 0.1285 - val_accuracy: 0.6625\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8708 - val_loss: 0.1146 - val_accuracy: 0.5702\n","Epoch 17/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8709 - val_loss: 0.1491 - val_accuracy: 0.5601\n","Epoch 18/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0159 - accuracy: 0.8693 - val_loss: 0.1125 - val_accuracy: 0.7319\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8676 - val_loss: 0.1792 - val_accuracy: 0.5919\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.8694 - val_loss: 0.1177 - val_accuracy: 0.6700\n","Epoch 21/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8704 - val_loss: 0.1423 - val_accuracy: 0.6019\n","Epoch 22/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0159 - accuracy: 0.8701 - val_loss: 0.1038 - val_accuracy: 0.6439\n","Epoch 23/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.8682 - val_loss: 0.0973 - val_accuracy: 0.7310\n","Model saved for fold 0 at model_fold_0.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["469/469 [==============================] - 1s 2ms/step\n","[array([0.01495947, 0.03231525, 0.01761941, 0.01430947, 0.00403356,\n","       0.00846814, 0.03749405]), array([0.01221762, 0.02247306, 0.01188413, 0.01136099, 0.00328906,\n","       0.00230588, 0.01850969]), array([0.03870645, 0.08503097, 0.03848143, 0.00861983, 0.00230311,\n","       0.00188614, 0.01472042]), array([0.03221133, 0.04818908, 0.03200253, 0.01368371, 0.00494441,\n","       0.00498527, 0.02206266]), array([0.0578315 , 0.12497769, 0.03907978, 0.25605412, 0.14548732,\n","       0.09716027, 0.01399624])]\n"]}],"source":["from joblib import dump, load\n","\n","mae_scores = []\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n","fold_number = 0\n","\n","early_stopping = EarlyStopping(monitor='val_accuracy',patience=10, restore_best_weights=True)\n","for train_index, test_index in KF.split(Input):\n","  X_train, X_val = Input[train_index], Input[test_index]\n","  Y_train, Y_val = Output[train_index], Output[test_index]\n","  print(X_train)\n","  print('***************')\n","  print(X_val)\n","  print('---------------')\n","  print(Y_train)\n","  print('***************')\n","  print(Y_val)\n","  print('===============')\n","  history2 = model2.fit(X_train, Y_train, epochs=50, batch_size=128, validation_data=(X_val, Y_val), callbacks=[early_stopping])\n","\n","  # Save the model at the end of training for each fold\n","  model_filename = f'model_fold_{fold_number}.h5'\n","  model2.save(model_filename)\n","  print(f'Model saved for fold {fold_number} at {model_filename}')\n","\n","\n","  predictions = model2.predict(X_val)\n","  mae = mean_absolute_error(Y_val, predictions, multioutput='raw_values')\n","  mae_scores.append(mae)\n","print(mae_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtjbEYBu_LG9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}