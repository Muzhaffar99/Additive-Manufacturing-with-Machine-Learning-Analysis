{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x_Ir0imBm-PK","colab":{"base_uri":"https://localhost:8080/","height":738},"executionInfo":{"status":"error","timestamp":1715793555258,"user_tz":-60,"elapsed":2378,"user":{"displayName":"Sidhant Manoj Barai","userId":"05466293579771935492"}},"outputId":"0a851296-fd81-4062-e1c5-be5c950eea00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Shareddrives/ACS6403 - Group Project/Deliverable 5 Final Project Report/Prediction Model\n","'Copy of Poly_model_0.joblib'\t       'Copy of SVM_model_6.joblib'\n","'Copy of Poly_model_1.joblib'\t       'Copy of SVM_model_7.joblib'\n","'Copy of Poly_model_2.joblib'\t       'Copy of System_model_1.joblib'\n","'Copy of Poly_model_3.joblib'\t       'Copy of System_model_2.joblib'\n","'Copy of Poly_model_4.joblib'\t       'Copy of System_model_3.joblib'\n","'Copy of Poly_model_5.joblib'\t       'Copy of System_model_4.joblib'\n","'Copy of Poly_model_6.joblib'\t       'Copy of System_model_5.joblib'\n","'Copy of Poly_model_7.joblib'\t       'Copy of System_model_6.joblib'\n","'Copy of randomforest_model_1.joblib'  'Copy of System_model_7.joblib'\n","'Copy of randomforest_model_2.joblib'  'Deep Feedforward Network'\n","'Copy of randomforest_model_3.joblib'   input_data_normalized.csv\n","'Copy of randomforest_model_4.joblib'   input_data_normalized.txt\n","'Copy of randomforest_model_5.joblib'   model_results.pdf\n","'Copy of randomforest_model_6.joblib'   model_text_summary.pdf\n","'Copy of randomforest_model_7.joblib'   output_data_normalized.csv\n","'Copy of SVM_model_1.joblib'\t        output_data_normalized.txt\n","'Copy of SVM_model_2.joblib'\t       'Polynomial Regression'\n","'Copy of SVM_model_3.joblib'\t       'Random Forest'\n","'Copy of SVM_model_4.joblib'\t       'Support Vector Machine.ipynb'\n","'Copy of SVM_model_5.joblib'\n"]},{"output_type":"error","ename":"ValueError","evalue":"shapes (2,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e1060ffa5ff8>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Handle the VARResults separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'VARResults'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust 'steps' as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Select the first step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36mforecast\u001b[0;34m(self, y, steps, exog_future)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mexog_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# TODO: use `mse` module-level function?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36mforecast\u001b[0;34m(y, coefs, trend_coefs, steps, exog)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# i=1 is coefs[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mforcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (2,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)"]}],"source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from joblib import load\n","import numpy as np\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# Change directory to the location of the file\n","%cd /content/drive/Shareddrives/ACS6403 - Group Project/Deliverable 5 Final Project Report/Prediction Model/\n","\n","# List the files to confirm\n","!ls\n","\n","input_data_1 = '/content/drive/Shareddrives/ACS6403 - Group Project/Preprocessed Data/input_data.txt'  # Update the path\n","output_data_1 = '/content/drive/Shareddrives/ACS6403 - Group Project/Preprocessed Data/output_data.txt'  # Update the path\n","\n","# Load the input and output data\n","input_Data = pd.read_csv(input_data_1, sep=',')\n","input_Data.columns = ['Input 1', 'Input 2', 'Input 3']\n","\n","output_Data = pd.read_csv(output_data_1, sep='\\s+')\n","output_Data.columns = ['Output 1', 'Output 2', 'Output 3', 'Output 4', 'Output 5', 'Output 6', 'Output 7']\n","\n","# Initialize MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Scale input and output data\n","input_Data_normalized = scaler.fit_transform(input_Data)\n","input_Data_normalized = pd.DataFrame(input_Data_normalized, columns=input_Data.columns)\n","output_Data_normalized = scaler.fit_transform(output_Data)\n","output_Data_normalized = pd.DataFrame(output_Data_normalized, columns=output_Data.columns)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(input_Data_normalized, output_Data_normalized, test_size=0.2, random_state=42)\n","\n","# List of algorithms\n","algorithms =  ['Poly','randomforest','SVM']\n","\n","# Load models and store their predictions\n","all_predictions = []\n","\n","for algo_name in algorithms:\n","    for index in range(1, 7):  # Assuming there are 7 models per algorithm\n","        filename = f'Copy of {algo_name}_model_{index}.joblib'\n","        model = load(filename)\n","\n","        # Check the model type and predict accordingly\n","        if hasattr(model, 'predict'):\n","            predictions = model.predict(X_test)\n","        else:\n","            # Handle the VARResults separately\n","            if 'VARResults' in str(type(model)):\n","                predictions = model.forecast(X_test.values, steps=1)  # Adjust 'steps' as needed\n","                predictions = predictions[0]  # Select the first step\n","            else:\n","                raise TypeError(f'Unsupported model type: {type(model)}')\n","\n","        all_predictions.append(predictions.reshape(-1, 1))\n","\n","# Combine all predictions into a single matrix\n","combined_predictions = np.hstack(all_predictions)\n","print(combined_predictions)\n","\n","# Continue with train-test split for combined predictions\n","X_train_preds, X_test_preds, y_train_preds, y_test_preds = train_test_split(combined_predictions, y_test, test_size=0.5, random_state=42)\n","print(\"X_train_preds shape:\", X_train_preds.shape)\n","print(\"y_train_preds shape:\", y_train_preds.shape)\n","print(\"X_test_preds shape:\", X_test_preds.shape)\n","print(\"y_test_preds shape:\", y_test_preds.shape)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"do1oYsi9RDWv","executionInfo":{"status":"ok","timestamp":1715793605382,"user_tz":-60,"elapsed":8898,"user":{"displayName":"Muzhaffar Maruf Ibrahim","userId":"13211234798137897760"}},"outputId":"dbaeef2c-4c64-4673-dcfb-f31d18d32a19"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Initialize the Decision Tree Regressor\n","regressor = DecisionTreeRegressor(random_state=42)\n","\n","# Train the model using all target columns\n","regressor.fit(X_train_preds, y_train_preds)\n","\n","# Predict on the test data\n","predictions = regressor.predict(X_test_preds)\n","\n","# Evaluate the model using Mean Squared Error and Mean Absolute Error\n","mse = mean_squared_error(y_test_preds, predictions, multioutput='raw_values')\n","mae = mean_absolute_error(y_test_preds, predictions, multioutput='raw_values')\n","print(f'Mean Squared Error for each output: {mse}')\n","print(f'Mean Absolute Error for each output: {mae}')\n","\n","# Optionally, compute an average MSE and MAE\n","average_mse = np.mean(mse)\n","average_mae = np.mean(mae)\n","print(f'Average Mean Squared Error: {average_mse}')\n","print(f'Average Mean Absolute Error: {average_mae}')\n","\n","models = []\n","mse_scores = []\n","mae_scores = []\n","\n","# Train one Decision Tree Regressor for each target and evaluate\n","for i in range(y_train_preds.shape[1]):\n","    model = DecisionTreeRegressor(random_state=42)\n","    model.fit(X_train_preds, y_train_preds.iloc[:, i])  # Train model on each target column\n","    pred = model.predict(X_test_preds)\n","\n","    # Calculate MSE and MAE\n","    mse = mean_squared_error(y_test_preds.iloc[:, i], pred)\n","    mae = mean_absolute_error(y_test_preds.iloc[:, i], pred)\n","    models.append(model)\n","    mse_scores.append(mse)\n","    mae_scores.append(mae)\n","\n","    # Plot predictions vs true values\n","    plt.figure(figsize=(10, 6))\n","    plt.scatter(y_test_preds.iloc[:, i], pred, edgecolor='k', alpha=0.6, label='Predictions')\n","    plt.plot(y_test_preds.iloc[:, i], y_test_preds.iloc[:, i], 'r--', label='Actual')\n","    plt.title(f'Regression Results for Output Column {i+1}')\n","    plt.xlabel('Actual Values')\n","    plt.ylabel('Predicted Values')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    print(f'MSE for output column {i+1}: {mse}')\n","    print(f'MAE for output column {i+1}: {mae}')\n","\n","# Optionally, average the MSE and MAE scores for an overall performance metric\n","average_mse = sum(mse_scores) / len(mse_scores)\n","average_mae = sum(mae_scores) / len(mae_scores)\n","print(f'Average Mean Squared Error: {average_mse}')\n","print(f'Average Mean Absolute Error: {average_mae}')"],"metadata":{"id":"5AhKajfpBA6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Assuming `model` is your trained neural network and `X_test` is your test dataset\n","# Let's say we're interested in the first feature column for sensitivity analysis\n","feature_index = 0  # Index of the feature to analyze\n","values = np.linspace(start=np.min(X_test[:, feature_index]),\n","                     stop=np.max(X_test[:, feature_index]),\n","                     num=100)  # Create 100 points between min and max\n","\n","outputs = []\n","for val in values:\n","    X_temp = X_test.copy()\n","    X_temp[:, feature_index] = val  # Set all instances of the selected feature to `val`\n","    pred = model.predict(X_temp)\n","    outputs.append(np.mean(pred))  # Store the average prediction (or choose another summary statistic)\n","\n","# Plot the results\n","plt.figure(figsize=(10, 6))\n","plt.plot(values, outputs, 'b-')\n","plt.xlabel(f'Value of Feature {feature_index}')\n","plt.ylabel('Predicted Output')\n","plt.title('Sensitivity Analysis of Feature ' + str(feature_index))\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"GQDRi8NU9Cs1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}